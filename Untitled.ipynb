{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek, monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "anonymous-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Wrangling Data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nonprofit-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    create a spark session\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Function: Fetch data from song_data folder in S3 bucket and extract columns for songs and artists tables. \n",
    "    Write data into parquet files and load to S3 bucket\n",
    "    \n",
    "    parameter list\n",
    "    \n",
    "    spark:        session, spark session has been created. \n",
    "    input_data:   string of path, a path point to S3 bucket.\n",
    "    output_data:  string of path, a path point to destination in S3.\n",
    "           \n",
    "    \"\"\"\n",
    "    # get filepath to song data file\n",
    "    song_data = input_data + 'song_data/*/*/*/*.json'\n",
    "    \n",
    "    # read song data file\n",
    "    df = spark.read.json(song_data)\n",
    "\n",
    "    # extract columns to create songs table\n",
    "    songs_table = df.select('song_id', 'title','artist_id','year', 'duration').dropDuplicates()\n",
    "              \n",
    "    songs_table.createOrReplaceTempView('songs')\n",
    "    \n",
    "    # write songs table to parquet files partitioned by year and artist\n",
    "    songs_table.write.partitionBy('year', 'artist_id').parquet(os.path.join(output_data, 'songs/songs.parquet'), 'overwrite')\n",
    "\n",
    "    # extract columns to create artists table\n",
    "    artists_table = df.select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude')\\\n",
    "                      .withColumnRenamed('artist_name', 'name')\\\n",
    "                      .withColumnRenamed('artist_location', 'location')\\\n",
    "                      .withColumnRenamed('artist_latitude', 'latitude')\\\n",
    "                      .withColumnRenamed('artist_longitude', 'longitude')\\\n",
    "                      .dropDuplicates()\n",
    "    artists_table.createOrReplaceTempView('artists')\n",
    " \n",
    "    # write artists table to parquet files\n",
    "    artists_table.write.parquet(os.path.join(output_data, 'artists/artists.parquet'), 'overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selected-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "    spark = create_spark_session()\n",
    "#     input_data = \"s3a://udacity-dend/\"\n",
    "    input_data = \"./data/\"\n",
    "#     output_data = \"s3a://lj_loaded_data/\"\n",
    "    output_data = \"./data/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "optimum-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = input_data + 'log_data/*.json'\n",
    "\n",
    "# read log data file\n",
    "df = spark.read.json(log_data)\n",
    "\n",
    "# filter by actions for song plays\n",
    "df_actions = df.filter(df.page == 'NextSong')\\\n",
    "               .select('ts', 'userId', 'level', 'song', 'artist', 'sessionId', 'length', 'location', 'userAgent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daily-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    " # extract columns for users table    \n",
    "users_table = df.select('userId', 'firstName', 'lastName', 'gender', 'level').dropDuplicates()\n",
    "\n",
    "users_table.createOrReplaceTempView('users')\n",
    "\n",
    "# write users table to parquet files\n",
    "users_table.write.parquet(os.path.join(output_data, 'users/users.parquet'), 'overwrite')\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x: str(int(int(x) / 1000)))\n",
    "df_actions = df_actions.withColumn('timestamp', get_timestamp(df_actions.ts)) \n",
    "\n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda x: str(datetime.fromtimestamp(int(x)/1000)))\n",
    "df_actions = df_actions.withColumn('datetime', get_datetime(df_actions.ts)) \n",
    "\n",
    "# extract columns to create time table\n",
    "time_table = df_actions.select('datetime')\\\n",
    "                       .withColumn('start_time', df_actions.datetime)\\\n",
    "                       .withColumn('hour', hour('datetime'))\\\n",
    "                       .withColumn('day', dayofmonth('datetime'))\\\n",
    "                       .withColumn('week', weekofyear('datetime'))\\\n",
    "                       .withColumn('month', month('datetime'))\\\n",
    "                       .withColumn('year', year('datetime'))\\\n",
    "                       .withColumn('weekday', dayofweek('datetime'))\\\n",
    "                       .dropDuplicates()\n",
    "\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy('year', 'month')\\\n",
    "                .parquet(os.path.join(output_data, 'time/time.parquet'), 'overwrite')\n",
    "\n",
    "# read in song data to use for songplays table\n",
    "df_songs = spark.read.json(input_data + 'song_data/*/*/*/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hourly-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_songs.dropDuplicates()\n",
    "df_songs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cleared-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_actions.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "under-scanning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>userId</th>\n",
       "      <th>level</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>length</th>\n",
       "      <th>location</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1542241826796</td>\n",
       "      <td>26</td>\n",
       "      <td>free</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>Harmonia</td>\n",
       "      <td>583</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>1542241826</td>\n",
       "      <td>2018-11-14 18:30:26.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1542242481796</td>\n",
       "      <td>26</td>\n",
       "      <td>free</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>583</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>1542242481</td>\n",
       "      <td>2018-11-14 18:41:21.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1542242741796</td>\n",
       "      <td>26</td>\n",
       "      <td>free</td>\n",
       "      <td>Marry Me</td>\n",
       "      <td>Train</td>\n",
       "      <td>583</td>\n",
       "      <td>205.45261</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>1542242741</td>\n",
       "      <td>2018-11-14 18:45:41.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1542253449796</td>\n",
       "      <td>61</td>\n",
       "      <td>free</td>\n",
       "      <td>Blackbird</td>\n",
       "      <td>Sony Wonder</td>\n",
       "      <td>597</td>\n",
       "      <td>218.06975</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542253449</td>\n",
       "      <td>2018-11-14 21:44:09.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542260935796</td>\n",
       "      <td>80</td>\n",
       "      <td>paid</td>\n",
       "      <td>Best Of Both Worlds (Remastered Album Version)</td>\n",
       "      <td>Van Halen</td>\n",
       "      <td>602</td>\n",
       "      <td>289.38404</td>\n",
       "      <td>Portland-South Portland, ME</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542260935</td>\n",
       "      <td>2018-11-14 23:48:55.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1542281853796</td>\n",
       "      <td>16</td>\n",
       "      <td>paid</td>\n",
       "      <td>Suicide</td>\n",
       "      <td>Jedi Mind Tricks</td>\n",
       "      <td>575</td>\n",
       "      <td>232.88118</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542281853</td>\n",
       "      <td>2018-11-15 05:37:33.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1542281872796</td>\n",
       "      <td>80</td>\n",
       "      <td>paid</td>\n",
       "      <td>Stella By Starlight</td>\n",
       "      <td>Miles Davis</td>\n",
       "      <td>611</td>\n",
       "      <td>285.20444</td>\n",
       "      <td>Portland-South Portland, ME</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542281872</td>\n",
       "      <td>2018-11-15 05:37:52.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1542281972796</td>\n",
       "      <td>30</td>\n",
       "      <td>paid</td>\n",
       "      <td>Nothin' On You [feat. Bruno Mars] (Album Version)</td>\n",
       "      <td>B.o.B</td>\n",
       "      <td>324</td>\n",
       "      <td>269.63546</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...</td>\n",
       "      <td>1542281972</td>\n",
       "      <td>2018-11-15 05:39:32.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1542282085796</td>\n",
       "      <td>16</td>\n",
       "      <td>paid</td>\n",
       "      <td>I And Love And You</td>\n",
       "      <td>The Avett Brothers</td>\n",
       "      <td>575</td>\n",
       "      <td>300.85179</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542282085</td>\n",
       "      <td>2018-11-15 05:41:25.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1542282157796</td>\n",
       "      <td>80</td>\n",
       "      <td>paid</td>\n",
       "      <td>Caprice viennois op.2</td>\n",
       "      <td>Joshua Bell / Paul Coker</td>\n",
       "      <td>611</td>\n",
       "      <td>275.93098</td>\n",
       "      <td>Portland-South Portland, ME</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>1542282157</td>\n",
       "      <td>2018-11-15 05:42:37.796000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ts userId level  \\\n",
       "0   1542241826796     26  free   \n",
       "1   1542242481796     26  free   \n",
       "2   1542242741796     26  free   \n",
       "3   1542253449796     61  free   \n",
       "4   1542260935796     80  paid   \n",
       "..            ...    ...   ...   \n",
       "95  1542281853796     16  paid   \n",
       "96  1542281872796     80  paid   \n",
       "97  1542281972796     30  paid   \n",
       "98  1542282085796     16  paid   \n",
       "99  1542282157796     80  paid   \n",
       "\n",
       "                                                 song  \\\n",
       "0                                       Sehr kosmisch   \n",
       "1                                     The Big Gundown   \n",
       "2                                            Marry Me   \n",
       "3                                           Blackbird   \n",
       "4      Best Of Both Worlds (Remastered Album Version)   \n",
       "..                                                ...   \n",
       "95                                            Suicide   \n",
       "96                                Stella By Starlight   \n",
       "97  Nothin' On You [feat. Bruno Mars] (Album Version)   \n",
       "98                                 I And Love And You   \n",
       "99                              Caprice viennois op.2   \n",
       "\n",
       "                      artist  sessionId     length  \\\n",
       "0                   Harmonia        583  655.77751   \n",
       "1                The Prodigy        583  260.07465   \n",
       "2                      Train        583  205.45261   \n",
       "3                Sony Wonder        597  218.06975   \n",
       "4                  Van Halen        602  289.38404   \n",
       "..                       ...        ...        ...   \n",
       "95          Jedi Mind Tricks        575  232.88118   \n",
       "96               Miles Davis        611  285.20444   \n",
       "97                     B.o.B        324  269.63546   \n",
       "98        The Avett Brothers        575  300.85179   \n",
       "99  Joshua Bell / Paul Coker        611  275.93098   \n",
       "\n",
       "                                location  \\\n",
       "0     San Jose-Sunnyvale-Santa Clara, CA   \n",
       "1     San Jose-Sunnyvale-Santa Clara, CA   \n",
       "2     San Jose-Sunnyvale-Santa Clara, CA   \n",
       "3   Houston-The Woodlands-Sugar Land, TX   \n",
       "4            Portland-South Portland, ME   \n",
       "..                                   ...   \n",
       "95                 Birmingham-Hoover, AL   \n",
       "96           Portland-South Portland, ME   \n",
       "97    San Jose-Sunnyvale-Santa Clara, CA   \n",
       "98                 Birmingham-Hoover, AL   \n",
       "99           Portland-South Portland, ME   \n",
       "\n",
       "                                            userAgent   timestamp  \\\n",
       "0   \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...  1542241826   \n",
       "1   \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...  1542242481   \n",
       "2   \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...  1542242741   \n",
       "3   \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542253449   \n",
       "4   \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542260935   \n",
       "..                                                ...         ...   \n",
       "95  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542281853   \n",
       "96  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542281872   \n",
       "97  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  1542281972   \n",
       "98  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542282085   \n",
       "99  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  1542282157   \n",
       "\n",
       "                      datetime  \n",
       "0   2018-11-14 18:30:26.796000  \n",
       "1   2018-11-14 18:41:21.796000  \n",
       "2   2018-11-14 18:45:41.796000  \n",
       "3   2018-11-14 21:44:09.796000  \n",
       "4   2018-11-14 23:48:55.796000  \n",
       "..                         ...  \n",
       "95  2018-11-15 05:37:33.796000  \n",
       "96  2018-11-15 05:37:52.796000  \n",
       "97  2018-11-15 05:39:32.796000  \n",
       "98  2018-11-15 05:41:25.796000  \n",
       "99  2018-11-15 05:42:37.796000  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unauthorized-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist_id='ARDR4AC1187FB371A1', artist_latitude=None, artist_location='', artist_longitude=None, artist_name='Montserrat Caballé;Placido Domingo;Vicente Sardinero;Judith Blegen;Sherrill Milnes;Georg Solti', duration=511.16363, num_songs=1, song_id='SOBAYLL12A8C138AF9', title='Sono andati? Fingevo di dormire', year=0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "regulated-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_song_actions = df_actions.join(df_songs, (df_actions['artist'] == df_songs['artist_name'])\n",
    "                                  & (df_actions['song'] == df_songs['title'])\n",
    "                                  & (df_actions['length'] == df_songs['duration']),'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "biological-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = df_song_actions.select(\n",
    "        col('datetime').alias('start_time'),\n",
    "        col('userId').alias('user_id'),\n",
    "        col('level').alias('level'),\n",
    "        col('song_id').alias('song_id'),\n",
    "        col('artist_id').alias('artist_id'),\n",
    "        col('sessionId').alias('session_id'),\n",
    "        col('location').alias('location'),\n",
    "        col('userAgent').alias('user_agent')\n",
    "    ).withColumn('songplay_id', monotonically_increasing_id())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "single-annual",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'songplays_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4361128e2b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write songplays table to parquet files partitioned by year and month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msongplays_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'songplays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'songplays_table' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.createOrReplaceTempView('songplays')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = time_table.alias('timetable')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table.write.partitionBy(\n",
    "    'year', 'month'\n",
    ").parquet(os.path.join(output_data, 'songplays/songplays.parquet'), 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Function: Extract data from log_data files for user and time tables. From both log_data and song_data files get data for songplays     table. Data written into parquet files and load into S3 bucket\n",
    "    \n",
    "    Prameter list\n",
    "    spark:        session, spark session has been created. \n",
    "    input_data:   string of path, a path point to S3 bucket.\n",
    "    output_data:  string of path, a path point to destination in S3.\n",
    "    \n",
    "    \"\"\"\n",
    "    # get filepath to log data file\n",
    "    log_data = input_data + 'log_data/*.json'\n",
    "\n",
    "    # read log data file\n",
    "    df = spark.read.json(log_data)\n",
    "    \n",
    "    # filter by actions for song plays\n",
    "    df_actions = df.filter(df.page == 'NextSong')\\\n",
    "                   .select('ts', 'userId', 'level', 'song', 'artist', 'sessionId', 'location', 'userAgent')\n",
    "\n",
    "    # extract columns for users table    \n",
    "    users_table = df.select('userId', 'firstName', 'lastName', 'gender', 'level').dropDuplicates()\n",
    "    \n",
    "    users_table.createOrReplaceTempView('users')\n",
    "    \n",
    "    # write users table to parquet files\n",
    "    users_table.write.parquet(os.path.join(output_data, 'users/users.parquet'), 'overwrite')\n",
    "\n",
    "    # create timestamp column from original timestamp column\n",
    "    get_timestamp = udf(lambda x: str(int(int(x) / 1000)))\n",
    "    df_actions = df_actions.withColumn('timestamp', get_timestamp(df_actions.ts)) \n",
    "    \n",
    "    # create datetime column from original timestamp column\n",
    "    get_datetime = udf(lambda x: str(datetime.fromtimestamp(int(x)/1000)))\n",
    "    df_actions = df_actions.withColumn('datetime', get_datetime(df_actions.ts)) \n",
    "    \n",
    "    # extract columns to create time table\n",
    "    time_table = df_actions.select('datetime')\\\n",
    "                           .withColumn('start_time', df_actions.datetime)\\\n",
    "                           .withColumn('hour', hour('datetime'))\\\n",
    "                           .withColumn('day', dayofmonth('datetime'))\\\n",
    "                           .withColumn('week', weekofyear('datetime'))\\\n",
    "                           .withColumn('month', month('datetime'))\\\n",
    "                           .withColumn('year', year('datetime'))\\\n",
    "                           .withColumn('weekday', dayofweek('datetime'))\\\n",
    "                           .dropDuplicates()\n",
    "    \n",
    "    # write time table to parquet files partitioned by year and month\n",
    "    time_table.write.partitionBy('year', 'month')\\\n",
    "                    .parquet(os.path.join(output_data, 'time/time.parquet'), 'overwrite')\n",
    "\n",
    "    # read in song data to use for songplays table\n",
    "    df_songs = spark.read.json(input_data + 'song_data/*/*/*/*.json')\n",
    "\n",
    "    # extract columns from joined song and log datasets to create songplays table \n",
    "    df_song_actions = df_actions.join(df_songs, df_actions['artist'] == df_songs['artist_name'],'inner')\n",
    "    songplays_table = df_song_actions.select(\n",
    "        col('df_actions.datetime').alias('start_time'),\n",
    "        col('df_actions.userId').alias('user_id'),\n",
    "        col('df_actions.level').alias('level'),\n",
    "        col('df_songs.song_id').alias('song_id'),\n",
    "        col('df_songs.artist_id').alias('artist_id'),\n",
    "        col('df_actions.sessionId').alias('session_id'),\n",
    "        col('df_actions.location').alias('location'),\n",
    "        col('df_actions.userAgent').alias('user_agent'),\n",
    "        year('log_df.datetime').alias('year'),\n",
    "        month('log_df.datetime').alias('month')\n",
    "    ).withColumn('songplay_id', monotonically_increasing_id())\n",
    "    \n",
    "\n",
    "    # write songplays table to parquet files partitioned by year and month\n",
    "    songplays_table.createOrReplaceTempView('songplays')\n",
    "    \n",
    "    time_table = time_table.alias('timetable')\n",
    "    \n",
    "    songplays_table.write.partitionBy(\n",
    "        'year', 'month'\n",
    "    ).parquet(os.path.join(output_data, 'songplays/songplays.parquet'), 'overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-lingerie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    Funtions:\n",
    "    * Get or create a spark session\n",
    "    * Read the song and log data from S3\n",
    "    * Transform data into dimension and fact tables\n",
    "    * Wrote into parquet files\n",
    "    * Load parquet files to S3\n",
    "    '''\n",
    "    spark = create_spark_session()\n",
    "#     input_data = \"s3a://udacity-dend/\"\n",
    "    input_data = \"./data/\"\n",
    "#     output_data = \"s3a://lj_loaded_data/\"\n",
    "    output_data = \"./data/output/\"\n",
    "    \n",
    "    process_song_data(spark, input_data, output_data)    \n",
    "    process_log_data(spark, input_data, output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-checklist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
